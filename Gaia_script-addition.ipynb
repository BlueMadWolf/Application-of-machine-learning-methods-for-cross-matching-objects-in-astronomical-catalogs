{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import v_measure_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import completeness_score\n",
    "from sklearn.metrics import homogeneity_score\n",
    "\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import Sequential\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#построение диаграммы\n",
    "def barplot(x_data, y_data, error_data, x_label=\"\", y_label=\"\", title=\"\", cnt_l = 40, cnt_r = 15):\n",
    "    fig, ax = plt.subplots(figsize = (cnt_l, cnt_r))\n",
    "    # Draw bars, position them in the center of the tick mark on the x-axis\n",
    "    ax.bar(x_data, y_data, color = '#539caf', align = 'center', width = 0.9)\n",
    "    # Draw error bars to show standard deviation, set ls to 'none'\n",
    "    # to remove line between points\n",
    "    ax.errorbar(x_data, y_data, color = '#297083', ls = 'none', lw = 2, capthick = 2)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    fig.savefig(title + '.png')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "#подсчет ошибок\n",
    "def count_errors(y_pred, y_true, n):\n",
    "    res = [0 for i in range(0,n)]\n",
    "    \n",
    "    cnt = 0\n",
    "    \n",
    "    for i in y_pred:\n",
    "        i_true = y_true.iloc[cnt]\n",
    "        if i != i_true:\n",
    "            c = res.pop(i_true)\n",
    "            res.insert(i_true, c + 1)\n",
    "        cnt = cnt + 1\n",
    "    return res\n",
    "\n",
    "#построение матрицы ошибок\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, normalize=False, title=None, savef = False, cmap=plt.cm.Blues):\n",
    "    \n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (20,20))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    if savef:\n",
    "        fig.savefig(title + '.png')\n",
    "    plt.show()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#обучение и проверка классификатора\n",
    "def learn_test_classifier(x_train, y_train, x_test, y_test, classifier):\n",
    "    classifier.fit(x_train, y_train)\n",
    "    res = classifier.predict(x_test)\n",
    "\n",
    "    print('hamming_loss: ', hamming_loss(y_test, res))\n",
    "    print('matthews_corrcoef: ', matthews_corrcoef(y_test, res))\n",
    "    print('accuracy_score: ', accuracy_score(y_test, res))\n",
    "    print('precision_score: ', precision_score(y_test, res, average='macro'))\n",
    "    print('recall_score: ', recall_score(y_test, res, average='macro'))\n",
    "    print('f1_score: ', f1_score(y_test, res, average='macro'))\n",
    "    \n",
    "    return res\n",
    "\n",
    "#прогон кластера\n",
    "def start_clustering(data, y_test, cluster):\n",
    "    cluster.fit(data)\n",
    "    res = cluster3.labels_\n",
    "\n",
    "    print('accuracy_score: ', accuracy_score(y_test, res))\n",
    "    print('hamming_loss: ', hamming_loss(y_test, res))\n",
    "    print('matthews_corrcoef: ', matthews_corrcoef(y_test, res))\n",
    "    print('precision_score: ', precision_score(y_test, res, average='macro'))\n",
    "    print('recall_score: ', recall_score(y_test, res, average='macro'))\n",
    "    print('f1_score: ', f1_score(y_test, res, average='macro'))\n",
    "    print('completeness_score: ', completeness_score(y_test, res))\n",
    "    print('adjusted_rand_score: ', adjusted_rand_score(y_test, res))\n",
    "    print('v_measure_score: ', v_measure_score(y_test, res))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/Gaia/GaiaSource/GaiaSource0.csv' )\n",
    "s = 'Data/Gaia/GaiaSource/GaiaSource'\n",
    "for i in range(20,47):#47):\n",
    "    s1 = s + str(i) + '.csv'\n",
    "    data = data.append(pd.read_csv(s1), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solution_id</th>\n",
       "      <th>designation</th>\n",
       "      <th>source_id</th>\n",
       "      <th>random_index</th>\n",
       "      <th>ref_epoch</th>\n",
       "      <th>ra</th>\n",
       "      <th>ra_error</th>\n",
       "      <th>dec</th>\n",
       "      <th>dec_error</th>\n",
       "      <th>parallax</th>\n",
       "      <th>...</th>\n",
       "      <th>phot_proc_mode</th>\n",
       "      <th>radial_velocity</th>\n",
       "      <th>radial_velocity_error</th>\n",
       "      <th>rv_nb_transits</th>\n",
       "      <th>radius_val</th>\n",
       "      <th>radius_percentile_lower</th>\n",
       "      <th>radius_percentile_upper</th>\n",
       "      <th>lum_val</th>\n",
       "      <th>lum_percentile_lower</th>\n",
       "      <th>lum_percentile_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1635721458409799680</td>\n",
       "      <td>Gaia DR2 1000225938242805248</td>\n",
       "      <td>1000225938242805248</td>\n",
       "      <td>1197051105</td>\n",
       "      <td>2015.5</td>\n",
       "      <td>103.447529</td>\n",
       "      <td>0.041099</td>\n",
       "      <td>56.022025</td>\n",
       "      <td>0.045175</td>\n",
       "      <td>0.582790</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.024730</td>\n",
       "      <td>1.017359</td>\n",
       "      <td>1.038814</td>\n",
       "      <td>1.075774</td>\n",
       "      <td>0.801798</td>\n",
       "      <td>1.349751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1635721458409799680</td>\n",
       "      <td>Gaia DR2 1000383512003001728</td>\n",
       "      <td>1000383512003001728</td>\n",
       "      <td>598525552</td>\n",
       "      <td>2015.5</td>\n",
       "      <td>105.187856</td>\n",
       "      <td>0.016978</td>\n",
       "      <td>56.267982</td>\n",
       "      <td>0.016904</td>\n",
       "      <td>1.385686</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.388711</td>\n",
       "      <td>1.311143</td>\n",
       "      <td>1.453106</td>\n",
       "      <td>1.937890</td>\n",
       "      <td>1.852440</td>\n",
       "      <td>2.023341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1635721458409799680</td>\n",
       "      <td>Gaia DR2 1000274106300491264</td>\n",
       "      <td>1000274106300491264</td>\n",
       "      <td>299262776</td>\n",
       "      <td>2015.5</td>\n",
       "      <td>103.424758</td>\n",
       "      <td>0.464608</td>\n",
       "      <td>56.450903</td>\n",
       "      <td>0.582490</td>\n",
       "      <td>0.314035</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1635721458409799680</td>\n",
       "      <td>Gaia DR2 1000396156385741312</td>\n",
       "      <td>1000396156385741312</td>\n",
       "      <td>1148557518</td>\n",
       "      <td>2015.5</td>\n",
       "      <td>105.049751</td>\n",
       "      <td>0.838232</td>\n",
       "      <td>56.508777</td>\n",
       "      <td>0.744511</td>\n",
       "      <td>1.939951</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1635721458409799680</td>\n",
       "      <td>Gaia DR2 1000250024419296000</td>\n",
       "      <td>1000250024419296000</td>\n",
       "      <td>574278759</td>\n",
       "      <td>2015.5</td>\n",
       "      <td>103.352525</td>\n",
       "      <td>0.023159</td>\n",
       "      <td>56.395144</td>\n",
       "      <td>0.022836</td>\n",
       "      <td>0.747108</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.507958</td>\n",
       "      <td>1.435618</td>\n",
       "      <td>1.540208</td>\n",
       "      <td>2.427377</td>\n",
       "      <td>2.152597</td>\n",
       "      <td>2.702158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           solution_id                   designation            source_id  \\\n",
       "0  1635721458409799680  Gaia DR2 1000225938242805248  1000225938242805248   \n",
       "1  1635721458409799680  Gaia DR2 1000383512003001728  1000383512003001728   \n",
       "2  1635721458409799680  Gaia DR2 1000274106300491264  1000274106300491264   \n",
       "3  1635721458409799680  Gaia DR2 1000396156385741312  1000396156385741312   \n",
       "4  1635721458409799680  Gaia DR2 1000250024419296000  1000250024419296000   \n",
       "\n",
       "   random_index  ref_epoch          ra  ra_error        dec  dec_error  \\\n",
       "0    1197051105     2015.5  103.447529  0.041099  56.022025   0.045175   \n",
       "1     598525552     2015.5  105.187856  0.016978  56.267982   0.016904   \n",
       "2     299262776     2015.5  103.424758  0.464608  56.450903   0.582490   \n",
       "3    1148557518     2015.5  105.049751  0.838232  56.508777   0.744511   \n",
       "4     574278759     2015.5  103.352525  0.023159  56.395144   0.022836   \n",
       "\n",
       "   parallax  ...  phot_proc_mode  radial_velocity  radial_velocity_error  \\\n",
       "0  0.582790  ...               0              NaN                    NaN   \n",
       "1  1.385686  ...               0              NaN                    NaN   \n",
       "2  0.314035  ...               0              NaN                    NaN   \n",
       "3  1.939951  ...               0              NaN                    NaN   \n",
       "4  0.747108  ...               0              NaN                    NaN   \n",
       "\n",
       "   rv_nb_transits  radius_val  radius_percentile_lower  \\\n",
       "0               0    1.024730                 1.017359   \n",
       "1               0    1.388711                 1.311143   \n",
       "2               0         NaN                      NaN   \n",
       "3               0         NaN                      NaN   \n",
       "4               0    1.507958                 1.435618   \n",
       "\n",
       "   radius_percentile_upper   lum_val  lum_percentile_lower  \\\n",
       "0                 1.038814  1.075774              0.801798   \n",
       "1                 1.453106  1.937890              1.852440   \n",
       "2                      NaN       NaN                   NaN   \n",
       "3                      NaN       NaN                   NaN   \n",
       "4                 1.540208  2.427377              2.152597   \n",
       "\n",
       "   lum_percentile_upper  \n",
       "0              1.349751  \n",
       "1              2.023341  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4              2.702158  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns=['astrometric_gof_al', 'astrometric_chi2_al', 'astrometric_excess_noise',\n",
    "       'astrometric_excess_noise_sig', 'astrometric_params_solved',\n",
    "       'astrometric_primary_flag', 'astrometric_weight_al',\n",
    "       'astrometric_pseudo_colour', 'astrometric_pseudo_colour_error',\n",
    "       'mean_varpi_factor_al', 'astrometric_matched_observations',\n",
    "       'visibility_periods_used', 'astrometric_sigma5d_max',\n",
    "       'frame_rotator_object_type', 'matched_observations',\n",
    "       'duplicated_source', 'astrometric_n_obs_al', 'astrometric_n_obs_ac',\n",
    "       'astrometric_n_good_obs_al', 'astrometric_n_bad_obs_al', 'phot_g_n_obs',\n",
    "       'phot_g_mean_flux', 'phot_g_mean_flux_error',\n",
    "       'phot_g_mean_flux_over_error', 'phot_g_mean_mag', 'phot_bp_n_obs',\n",
    "       'phot_bp_mean_flux', 'phot_bp_mean_flux_error',\n",
    "       'phot_bp_mean_flux_over_error', 'phot_bp_mean_mag', 'phot_rp_n_obs',\n",
    "       'phot_rp_mean_flux', 'phot_rp_mean_flux_error',\n",
    "       'phot_rp_mean_flux_over_error', 'phot_rp_mean_mag',\n",
    "       'phot_bp_rp_excess_factor', 'bp_rp', 'bp_g', 'g_rp']) \n",
    "\n",
    "data = data.drop(columns=['rv_template_teff', 'rv_template_logg', 'rv_template_fe_h',\n",
    "       'phot_variable_flag', 'l', 'b', 'ecl_lon', 'ecl_lat', 'priam_flags',\n",
    "       'teff_val', 'teff_percentile_lower', 'teff_percentile_upper', 'a_g_val',\n",
    "       'a_g_percentile_lower', 'a_g_percentile_upper', 'e_bp_min_rp_val',\n",
    "       'e_bp_min_rp_percentile_lower', 'e_bp_min_rp_percentile_upper',\n",
    "       'flame_flags'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = ['radial_velocity', 'radial_velocity_error', 'rv_nb_transits','phot_proc_mode', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('Data/Gaia/light_curve/light_curves0.csv')\n",
    "\n",
    "s = 'Data/Gaia/light_curve/light_curves'\n",
    "for i in range(15,19):\n",
    "    s1 = s + str(i) + '.csv'\n",
    "    data1 = data1.append(pd.read_csv(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data_m = data.merge(data1, on='source_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m = data_m.drop(columns = ['solution_id_x', 'solution_id_y', 'rejected_by_photometry','rejected_by_variability', 'other_flags', 'random_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>ref_epoch</th>\n",
       "      <th>ra</th>\n",
       "      <th>ra_error</th>\n",
       "      <th>dec</th>\n",
       "      <th>dec_error</th>\n",
       "      <th>parallax</th>\n",
       "      <th>parallax_error</th>\n",
       "      <th>parallax_over_error</th>\n",
       "      <th>pmra</th>\n",
       "      <th>...</th>\n",
       "      <th>pmra_pmdec_corr</th>\n",
       "      <th>radius_val</th>\n",
       "      <th>lum_val</th>\n",
       "      <th>transit_id</th>\n",
       "      <th>band</th>\n",
       "      <th>time</th>\n",
       "      <th>mag</th>\n",
       "      <th>flux</th>\n",
       "      <th>flux_error</th>\n",
       "      <th>flux_over_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1762304559921296768</td>\n",
       "      <td>2015.5</td>\n",
       "      <td>311.392496</td>\n",
       "      <td>0.032176</td>\n",
       "      <td>14.861018</td>\n",
       "      <td>0.032321</td>\n",
       "      <td>1.146271</td>\n",
       "      <td>0.039372</td>\n",
       "      <td>29.11372</td>\n",
       "      <td>10.371885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021288</td>\n",
       "      <td>0.812044</td>\n",
       "      <td>0.373563</td>\n",
       "      <td>20229154356912906</td>\n",
       "      <td>G</td>\n",
       "      <td>1762.678844</td>\n",
       "      <td>15.579629</td>\n",
       "      <td>11053.368985</td>\n",
       "      <td>15.153247</td>\n",
       "      <td>729.43896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1762304559921296768</td>\n",
       "      <td>2015.5</td>\n",
       "      <td>311.392496</td>\n",
       "      <td>0.032176</td>\n",
       "      <td>14.861018</td>\n",
       "      <td>0.032321</td>\n",
       "      <td>1.146271</td>\n",
       "      <td>0.039372</td>\n",
       "      <td>29.11372</td>\n",
       "      <td>10.371885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021288</td>\n",
       "      <td>0.812044</td>\n",
       "      <td>0.373563</td>\n",
       "      <td>21845830561607793</td>\n",
       "      <td>G</td>\n",
       "      <td>1791.913111</td>\n",
       "      <td>15.568158</td>\n",
       "      <td>11170.774175</td>\n",
       "      <td>15.306830</td>\n",
       "      <td>729.79016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1762304559921296768</td>\n",
       "      <td>2015.5</td>\n",
       "      <td>311.392496</td>\n",
       "      <td>0.032176</td>\n",
       "      <td>14.861018</td>\n",
       "      <td>0.032321</td>\n",
       "      <td>1.146271</td>\n",
       "      <td>0.039372</td>\n",
       "      <td>29.11372</td>\n",
       "      <td>10.371885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021288</td>\n",
       "      <td>0.812044</td>\n",
       "      <td>0.373563</td>\n",
       "      <td>23127363079786977</td>\n",
       "      <td>G</td>\n",
       "      <td>1815.087231</td>\n",
       "      <td>15.579278</td>\n",
       "      <td>11056.943748</td>\n",
       "      <td>18.126910</td>\n",
       "      <td>609.97400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1762304559921296768</td>\n",
       "      <td>2015.5</td>\n",
       "      <td>311.392496</td>\n",
       "      <td>0.032176</td>\n",
       "      <td>14.861018</td>\n",
       "      <td>0.032321</td>\n",
       "      <td>1.146271</td>\n",
       "      <td>0.039372</td>\n",
       "      <td>29.11372</td>\n",
       "      <td>10.371885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021288</td>\n",
       "      <td>0.812044</td>\n",
       "      <td>0.373563</td>\n",
       "      <td>23131455361570703</td>\n",
       "      <td>G</td>\n",
       "      <td>1815.161233</td>\n",
       "      <td>15.565434</td>\n",
       "      <td>11198.833624</td>\n",
       "      <td>106.208811</td>\n",
       "      <td>105.44167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1762304559921296768</td>\n",
       "      <td>2015.5</td>\n",
       "      <td>311.392496</td>\n",
       "      <td>0.032176</td>\n",
       "      <td>14.861018</td>\n",
       "      <td>0.032321</td>\n",
       "      <td>1.146271</td>\n",
       "      <td>0.039372</td>\n",
       "      <td>29.11372</td>\n",
       "      <td>10.371885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021288</td>\n",
       "      <td>0.812044</td>\n",
       "      <td>0.373563</td>\n",
       "      <td>29804144275367582</td>\n",
       "      <td>G</td>\n",
       "      <td>1935.835025</td>\n",
       "      <td>15.584589</td>\n",
       "      <td>11002.988241</td>\n",
       "      <td>17.473031</td>\n",
       "      <td>629.71260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             source_id  ref_epoch          ra  ra_error        dec  dec_error  \\\n",
       "0  1762304559921296768     2015.5  311.392496  0.032176  14.861018   0.032321   \n",
       "1  1762304559921296768     2015.5  311.392496  0.032176  14.861018   0.032321   \n",
       "2  1762304559921296768     2015.5  311.392496  0.032176  14.861018   0.032321   \n",
       "3  1762304559921296768     2015.5  311.392496  0.032176  14.861018   0.032321   \n",
       "4  1762304559921296768     2015.5  311.392496  0.032176  14.861018   0.032321   \n",
       "\n",
       "   parallax  parallax_error  parallax_over_error       pmra  ...  \\\n",
       "0  1.146271        0.039372             29.11372  10.371885  ...   \n",
       "1  1.146271        0.039372             29.11372  10.371885  ...   \n",
       "2  1.146271        0.039372             29.11372  10.371885  ...   \n",
       "3  1.146271        0.039372             29.11372  10.371885  ...   \n",
       "4  1.146271        0.039372             29.11372  10.371885  ...   \n",
       "\n",
       "   pmra_pmdec_corr  radius_val   lum_val         transit_id  band  \\\n",
       "0         0.021288    0.812044  0.373563  20229154356912906     G   \n",
       "1         0.021288    0.812044  0.373563  21845830561607793     G   \n",
       "2         0.021288    0.812044  0.373563  23127363079786977     G   \n",
       "3         0.021288    0.812044  0.373563  23131455361570703     G   \n",
       "4         0.021288    0.812044  0.373563  29804144275367582     G   \n",
       "\n",
       "          time        mag          flux  flux_error  flux_over_error  \n",
       "0  1762.678844  15.579629  11053.368985   15.153247        729.43896  \n",
       "1  1791.913111  15.568158  11170.774175   15.306830        729.79016  \n",
       "2  1815.087231  15.579278  11056.943748   18.126910        609.97400  \n",
       "3  1815.161233  15.565434  11198.833624  106.208811        105.44167  \n",
       "4  1935.835025  15.584589  11002.988241   17.473031        629.71260  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_m = data_m.drop(columns = ['radius_percentile_lower','radius_percentile_upper','lum_percentile_lower','lum_percentile_upper'])\n",
    "data_m = data_m.drop(columns = ['designation'])# 'random_index', 'ref_epoch'\n",
    "data_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_m.columns:\n",
    "    if not i in ['phot_rp_n_obs', 'source_id','flux', 'flux_over_error', 'flux_error', 'time', 'mag', 'rejected_by_photometry','rejected_by_variability', 'band', 'random_index', 'ref_epoch', 'other_flags'] :\n",
    "        data_m[i] = data_m[i].apply(lambda x: x+random.uniform(-0.85, 1.255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = []\n",
    "\n",
    "for i in data_m['band'].drop_duplicates():\n",
    "    z1.append(i)\n",
    "\n",
    "def f1(x, z1):\n",
    "    return int(z1.index(x))\n",
    "\n",
    "data_m['band'] = data_m['band'].apply(lambda x: f1(x, z1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#выбираем только данные из заданной области\n",
    "ra = 310.7\n",
    "dec = 14.56\n",
    "\n",
    "pdata = []\n",
    "for i in range(0, len(data_m)):\n",
    "     if (abs(data_m.loc[i,'ra'] - ra) < 0.3) and (abs(data_m.loc[i,'dec'] - dec) < 0.3):\n",
    "            pdata.append(data_m.loc[i])\n",
    "pdata = pd.DataFrame(pdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#выбираем только данные из заданной области, которые будут являться примерами нераспознанных данных\n",
    "pdata1 = []\n",
    "for i in range(0, len(data_m)):\n",
    "     if (abs(data_m.loc[i,'ra'] - ra) < 0.6) and (abs(data_m.loc[i,'dec'] - dec) < 0.6) and (abs(data_m.loc[i,'ra'] - ra) >= 0.3) and (abs(data_m.loc[i,'dec'] - dec) >= 0.3) :\n",
    "            pdata1.append(data_m.loc[i])\n",
    "pdata1 = pd.DataFrame(pdata1)\n",
    "pdata1['source_id'] = len(data_m['source_id'].drop_duplicates())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m = pd.concat([pdata, pdata1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = []\n",
    "\n",
    "for i in data_m['source_id'].drop_duplicates():\n",
    "    z.append(i)\n",
    "\n",
    "def f(x, z):\n",
    "    return int(z.index(x))\n",
    "\n",
    "y = data_m['source_id']\n",
    "y = y.apply(lambda x: f(x, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(data_m['source_id'].drop_duplicates())\n",
    "data_m = data_m.drop(columns = ['source_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307\n",
      "1        0\n",
      "112      1\n",
      "232      2\n",
      "302      3\n",
      "431      4\n",
      "519      5\n",
      "606      6\n",
      "673      7\n",
      "772      8\n",
      "849      9\n",
      "938     10\n",
      "1070    11\n",
      "1134    12\n",
      "1288    13\n",
      "1331    14\n",
      "1458    15\n",
      "1520    16\n",
      "1608    17\n",
      "1717    18\n",
      "1784    19\n",
      "1932    20\n",
      "2047    21\n",
      "2112    22\n",
      "2257    23\n",
      "3397    24\n",
      "4017    25\n",
      "Name: source_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(len(data_m))\n",
    "y1 = y.apply(lambda x: x if x != max(y)  else max(y) - 1)\n",
    "print(y1.drop_duplicates())\n",
    "y = y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(data_m.columns)\n",
    "p = len(y.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Создаем основу для нашей модели. Для кросс-идентификации хорошо работает обычный многослойный персептрон\n",
    "def base_model(input_shape = (m,)):\n",
    "    input = Input(shape=input_shape)\n",
    "\n",
    "    x = Dense(m*p*5, activation='relu', use_bias=True)(input)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(150, activation='relu', use_bias=True)(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(p, activation='softmax')(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "#обучение модели жестким классам\n",
    "def train_cross_entropy(model, train_x, train_y, test_x, test_y, n_epoch = 50, b_size = 1000, b = True):\n",
    "    adam = optimizers.Adam()\n",
    "\n",
    "    model.compile(loss=losses.CategoricalCrossentropy(label_smoothing = 0),\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit( train_x, train_y, epochs= n_epoch, batch_size = b_size, \n",
    "                        validation_data = (test_x, test_y), verbose = b)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref_epoch</th>\n",
       "      <th>ra</th>\n",
       "      <th>ra_error</th>\n",
       "      <th>dec</th>\n",
       "      <th>dec_error</th>\n",
       "      <th>parallax</th>\n",
       "      <th>parallax_error</th>\n",
       "      <th>parallax_over_error</th>\n",
       "      <th>pmra</th>\n",
       "      <th>pmra_error</th>\n",
       "      <th>...</th>\n",
       "      <th>pmra_pmdec_corr</th>\n",
       "      <th>radius_val</th>\n",
       "      <th>lum_val</th>\n",
       "      <th>transit_id</th>\n",
       "      <th>band</th>\n",
       "      <th>time</th>\n",
       "      <th>mag</th>\n",
       "      <th>flux</th>\n",
       "      <th>flux_error</th>\n",
       "      <th>flux_over_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015.5</td>\n",
       "      <td>310.692360</td>\n",
       "      <td>0.929387</td>\n",
       "      <td>14.454485</td>\n",
       "      <td>0.698232</td>\n",
       "      <td>0.350792</td>\n",
       "      <td>-0.643130</td>\n",
       "      <td>30.224357</td>\n",
       "      <td>10.861849</td>\n",
       "      <td>1.250292</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115980</td>\n",
       "      <td>1.536240</td>\n",
       "      <td>1.284569</td>\n",
       "      <td>2.184583e+16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1791.913111</td>\n",
       "      <td>15.568158</td>\n",
       "      <td>11170.774175</td>\n",
       "      <td>15.306830</td>\n",
       "      <td>729.79016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015.5</td>\n",
       "      <td>310.802554</td>\n",
       "      <td>-0.572100</td>\n",
       "      <td>14.520946</td>\n",
       "      <td>0.410919</td>\n",
       "      <td>0.385993</td>\n",
       "      <td>0.514149</td>\n",
       "      <td>30.281564</td>\n",
       "      <td>10.926475</td>\n",
       "      <td>-0.564517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833209</td>\n",
       "      <td>0.246771</td>\n",
       "      <td>0.833002</td>\n",
       "      <td>2.312736e+16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1815.087231</td>\n",
       "      <td>15.579278</td>\n",
       "      <td>11056.943748</td>\n",
       "      <td>18.126910</td>\n",
       "      <td>609.97400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015.5</td>\n",
       "      <td>310.929765</td>\n",
       "      <td>1.006966</td>\n",
       "      <td>14.267927</td>\n",
       "      <td>-0.175774</td>\n",
       "      <td>2.254773</td>\n",
       "      <td>0.813130</td>\n",
       "      <td>30.002887</td>\n",
       "      <td>10.767074</td>\n",
       "      <td>0.626469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.597970</td>\n",
       "      <td>0.707193</td>\n",
       "      <td>0.449657</td>\n",
       "      <td>2.980824e+16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1935.909038</td>\n",
       "      <td>15.586536</td>\n",
       "      <td>10983.275883</td>\n",
       "      <td>24.302258</td>\n",
       "      <td>451.94467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015.5</td>\n",
       "      <td>310.657555</td>\n",
       "      <td>-0.301927</td>\n",
       "      <td>14.855281</td>\n",
       "      <td>0.858878</td>\n",
       "      <td>0.989193</td>\n",
       "      <td>-0.103455</td>\n",
       "      <td>29.182927</td>\n",
       "      <td>10.546380</td>\n",
       "      <td>-0.068250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.790571</td>\n",
       "      <td>1.581256</td>\n",
       "      <td>1.319417</td>\n",
       "      <td>3.828352e+16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2089.185611</td>\n",
       "      <td>15.545917</td>\n",
       "      <td>11401.962338</td>\n",
       "      <td>18.248400</td>\n",
       "      <td>624.81980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2015.5</td>\n",
       "      <td>310.715646</td>\n",
       "      <td>0.437061</td>\n",
       "      <td>14.559234</td>\n",
       "      <td>-0.518968</td>\n",
       "      <td>2.223881</td>\n",
       "      <td>0.940640</td>\n",
       "      <td>30.274087</td>\n",
       "      <td>10.350309</td>\n",
       "      <td>-0.714383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195978</td>\n",
       "      <td>0.490180</td>\n",
       "      <td>0.739701</td>\n",
       "      <td>3.889613e+16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2100.264019</td>\n",
       "      <td>16.102538</td>\n",
       "      <td>5006.567453</td>\n",
       "      <td>69.079940</td>\n",
       "      <td>72.47498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ref_epoch          ra  ra_error        dec  dec_error  parallax  \\\n",
       "1      2015.5  310.692360  0.929387  14.454485   0.698232  0.350792   \n",
       "2      2015.5  310.802554 -0.572100  14.520946   0.410919  0.385993   \n",
       "5      2015.5  310.929765  1.006966  14.267927  -0.175774  2.254773   \n",
       "8      2015.5  310.657555 -0.301927  14.855281   0.858878  0.989193   \n",
       "42     2015.5  310.715646  0.437061  14.559234  -0.518968  2.223881   \n",
       "\n",
       "    parallax_error  parallax_over_error       pmra  pmra_error  ...  \\\n",
       "1        -0.643130            30.224357  10.861849    1.250292  ...   \n",
       "2         0.514149            30.281564  10.926475   -0.564517  ...   \n",
       "5         0.813130            30.002887  10.767074    0.626469  ...   \n",
       "8        -0.103455            29.182927  10.546380   -0.068250  ...   \n",
       "42        0.940640            30.274087  10.350309   -0.714383  ...   \n",
       "\n",
       "    pmra_pmdec_corr  radius_val   lum_val    transit_id  band         time  \\\n",
       "1         -0.115980    1.536240  1.284569  2.184583e+16   0.0  1791.913111   \n",
       "2          0.833209    0.246771  0.833002  2.312736e+16   0.0  1815.087231   \n",
       "5          0.597970    0.707193  0.449657  2.980824e+16   0.0  1935.909038   \n",
       "8         -0.790571    1.581256  1.319417  3.828352e+16   0.0  2089.185611   \n",
       "42         0.195978    0.490180  0.739701  3.889613e+16   1.0  2100.264019   \n",
       "\n",
       "          mag          flux  flux_error  flux_over_error  \n",
       "1   15.568158  11170.774175   15.306830        729.79016  \n",
       "2   15.579278  11056.943748   18.126910        609.97400  \n",
       "5   15.586536  10983.275883   24.302258        451.94467  \n",
       "8   15.545917  11401.962338   18.248400        624.81980  \n",
       "42  16.102538   5006.567453   69.079940         72.47498  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ref_epoch', 'ra', 'ra_error', 'dec', 'dec_error', 'parallax',\n",
       "       'parallax_error', 'parallax_over_error', 'pmra', 'pmra_error', 'pmdec',\n",
       "       'pmdec_error', 'ra_dec_corr', 'ra_parallax_corr', 'ra_pmra_corr',\n",
       "       'ra_pmdec_corr', 'dec_parallax_corr', 'dec_pmra_corr', 'dec_pmdec_corr',\n",
       "       'parallax_pmra_corr', 'parallax_pmdec_corr', 'pmra_pmdec_corr',\n",
       "       'radius_val', 'lum_val', 'transit_id', 'band', 'time', 'mag', 'flux',\n",
       "       'flux_error', 'flux_over_error'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_m.columns\n",
    "#data_m = data_m.drop(columns = ['transit_id', 'band']) влияет на нейронку с помощью keras, но не влияет на svc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#делим данные на обучающую и тестовую выборки\n",
    "#делим данные на обучающую и тестовую выборки\n",
    "#в данном примере test_size = 0.7, эксперименты проводились и для test_size = 0.3, как описано в статье\n",
    "#на них же и подбиралась часть параметров\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_m, y, test_size=0.7, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#преобразуем данные в формат, подходящий для обучения модели\n",
    "\n",
    "new_y = []\n",
    "\n",
    "for i in y:\n",
    "    el = [0.0 for i in range(p)]\n",
    "    el[i] = 1.0\n",
    "    new_y.append(el)\n",
    "    \n",
    "cat_y = to_categorical(y.values)\n",
    "\n",
    "cat_train_y = to_categorical(y_train.values)\n",
    "cat_test_y = to_categorical(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_m.copy()\n",
    "for i in data.columns:\n",
    "    if not i in ['source_id', 'band', 'rejected_by_photometry','rejected_by_variability','other_flags']:\n",
    "        data[i] /= max(abs(data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn: \n",
      "hamming_loss:  0.9023255813953488\n",
      "matthews_corrcoef:  -0.01182154682901245\n",
      "accuracy_score:  0.09767441860465116\n",
      "precision_score:  0.033237548880137996\n",
      "recall_score:  0.05283605283605283\n",
      "f1_score:  0.02953296703296704\n",
      "\n",
      "dt:\n",
      "hamming_loss:  0.3627906976744186\n",
      "matthews_corrcoef:  0.5342900682497984\n",
      "accuracy_score:  0.6372093023255814\n",
      "precision_score:  0.30003468753468754\n",
      "recall_score:  0.3267843267843268\n",
      "f1_score:  0.2939235601000307\n",
      "\n",
      "rf:\n",
      "hamming_loss: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.4372093023255814\n",
      "matthews_corrcoef:  0.3702788640069885\n",
      "accuracy_score:  0.5627906976744186\n",
      "precision_score:  0.30471701501113263\n",
      "recall_score:  0.2939060939060939\n",
      "f1_score:  0.2648137973137973\n",
      "\n",
      "xgb: \n",
      "hamming_loss:  0.3116279069767442\n",
      "matthews_corrcoef:  0.5985158879472957\n",
      "accuracy_score:  0.6883720930232559\n",
      "precision_score:  0.34847677075399847\n",
      "recall_score:  0.3894438894438894\n",
      "f1_score:  0.34027076089145736\n",
      "\n",
      "lgb: \n",
      "hamming_loss:  0.3116279069767442\n",
      "matthews_corrcoef:  0.602112947574661\n",
      "accuracy_score:  0.6883720930232559\n",
      "precision_score:  0.3920551670551671\n",
      "recall_score:  0.4098679098679099\n",
      "f1_score:  0.35738645200887764\n",
      "\n",
      "svc: \n",
      "[LibSVM]hamming_loss:  0.5395348837209303\n",
      "matthews_corrcoef:  0.0\n",
      "accuracy_score:  0.4604651162790698\n",
      "precision_score:  0.017710196779964223\n",
      "recall_score:  0.038461538461538464\n",
      "f1_score:  0.02425281724644782\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92 samples, validate on 215 samples\n",
      "Epoch 1/30\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 1884248860524544.0000 - accuracy: 0.0435 - val_loss: 4738510179270656.0000 - val_accuracy: 0.4605\n",
      "Epoch 2/30\n",
      "92/92 [==============================] - 0s 282us/step - loss: 4617685769912320.0000 - accuracy: 0.4783 - val_loss: 2781867229052928.0000 - val_accuracy: 0.4605\n",
      "Epoch 3/30\n",
      "92/92 [==============================] - 0s 282us/step - loss: 2923367342538752.0000 - accuracy: 0.4783 - val_loss: 2817865497444352.0000 - val_accuracy: 0.0047\n",
      "Epoch 4/30\n",
      "92/92 [==============================] - 0s 271us/step - loss: 2732700859367424.0000 - accuracy: 0.0217 - val_loss: 1932156939010048.0000 - val_accuracy: 0.0233\n",
      "Epoch 5/30\n",
      "92/92 [==============================] - 0s 249us/step - loss: 2245917990191104.0000 - accuracy: 0.0326 - val_loss: 1169716357890048.0000 - val_accuracy: 0.0140\n",
      "Epoch 6/30\n",
      "92/92 [==============================] - 0s 282us/step - loss: 1771420472311808.0000 - accuracy: 0.0543 - val_loss: 446162444222464.0000 - val_accuracy: 0.0140\n",
      "Epoch 7/30\n",
      "92/92 [==============================] - 0s 304us/step - loss: 1187624626683904.0000 - accuracy: 0.1848 - val_loss: 880564395573248.0000 - val_accuracy: 0.4605\n",
      "Epoch 8/30\n",
      "92/92 [==============================] - 0s 293us/step - loss: 1174990846164992.0000 - accuracy: 0.3261 - val_loss: 1033578712399872.0000 - val_accuracy: 0.4605\n",
      "Epoch 9/30\n",
      "92/92 [==============================] - 0s 336us/step - loss: 1271990132408320.0000 - accuracy: 0.4348 - val_loss: 924864902856704.0000 - val_accuracy: 0.4605\n",
      "Epoch 10/30\n",
      "92/92 [==============================] - 0s 325us/step - loss: 1129394265391104.0000 - accuracy: 0.4457 - val_loss: 745222996754432.0000 - val_accuracy: 0.4605\n",
      "Epoch 11/30\n",
      "92/92 [==============================] - 0s 314us/step - loss: 861519638167552.0000 - accuracy: 0.3696 - val_loss: 542526175969280.0000 - val_accuracy: 0.4605\n",
      "Epoch 12/30\n",
      "92/92 [==============================] - 0s 293us/step - loss: 887956839596032.0000 - accuracy: 0.2717 - val_loss: 355608830148608.0000 - val_accuracy: 0.4605\n",
      "Epoch 13/30\n",
      "92/92 [==============================] - 0s 282us/step - loss: 552501841494016.0000 - accuracy: 0.2609 - val_loss: 265407118180352.0000 - val_accuracy: 0.4605\n",
      "Epoch 14/30\n",
      "92/92 [==============================] - 0s 358us/step - loss: 524668943466496.0000 - accuracy: 0.1413 - val_loss: 220613293637632.0000 - val_accuracy: 0.4605\n",
      "Epoch 15/30\n",
      "92/92 [==============================] - 0s 564us/step - loss: 402638118060032.0000 - accuracy: 0.1413 - val_loss: 164817977475072.0000 - val_accuracy: 0.4605\n",
      "Epoch 16/30\n",
      "92/92 [==============================] - 0s 444us/step - loss: 299610509672448.0000 - accuracy: 0.1957 - val_loss: 112214484713472.0000 - val_accuracy: 0.4605\n",
      "Epoch 17/30\n",
      "92/92 [==============================] - 0s 325us/step - loss: 220458221830144.0000 - accuracy: 0.2065 - val_loss: 39695752888320.0000 - val_accuracy: 0.4605\n",
      "Epoch 18/30\n",
      "92/92 [==============================] - 0s 404us/step - loss: 133093855854592.0000 - accuracy: 0.1522 - val_loss: 3.2598 - val_accuracy: 0.0093\n",
      "Epoch 19/30\n",
      "92/92 [==============================] - 0s 304us/step - loss: 73130148102144.0000 - accuracy: 0.0978 - val_loss: 3.2598 - val_accuracy: 0.0093\n",
      "Epoch 20/30\n",
      "92/92 [==============================] - 0s 293us/step - loss: 25552316530688.0000 - accuracy: 0.0326 - val_loss: 3.2596 - val_accuracy: 0.0093\n",
      "Epoch 21/30\n",
      "92/92 [==============================] - 0s 336us/step - loss: 10277876662272.0000 - accuracy: 0.0109 - val_loss: 3.2594 - val_accuracy: 0.0093\n",
      "Epoch 22/30\n",
      "92/92 [==============================] - 0s 314us/step - loss: 5154921775104.0000 - accuracy: 0.0109 - val_loss: 3.2590 - val_accuracy: 0.0093\n",
      "Epoch 23/30\n",
      "92/92 [==============================] - 0s 347us/step - loss: 3.2585 - accuracy: 0.0109 - val_loss: 3.2587 - val_accuracy: 0.0047\n",
      "Epoch 24/30\n",
      "92/92 [==============================] - 0s 314us/step - loss: 41206317056.0000 - accuracy: 0.0217 - val_loss: 3.2582 - val_accuracy: 0.0419\n",
      "Epoch 25/30\n",
      "92/92 [==============================] - 0s 293us/step - loss: 3.2575 - accuracy: 0.0435 - val_loss: 3.2577 - val_accuracy: 0.0419\n",
      "Epoch 26/30\n",
      "92/92 [==============================] - 0s 282us/step - loss: 3.2569 - accuracy: 0.0435 - val_loss: 3.2572 - val_accuracy: 0.0419\n",
      "Epoch 27/30\n",
      "92/92 [==============================] - 0s 304us/step - loss: 3.2563 - accuracy: 0.0435 - val_loss: 3.2567 - val_accuracy: 0.0419\n",
      "Epoch 28/30\n",
      "92/92 [==============================] - 0s 325us/step - loss: 68169465856.0000 - accuracy: 0.0326 - val_loss: 3.2561 - val_accuracy: 0.0419\n",
      "Epoch 29/30\n",
      "92/92 [==============================] - 0s 271us/step - loss: 3.2550 - accuracy: 0.0435 - val_loss: 3.2555 - val_accuracy: 0.0419\n",
      "Epoch 30/30\n",
      "92/92 [==============================] - 0s 260us/step - loss: 3.2543 - accuracy: 0.0435 - val_loss: 3.2549 - val_accuracy: 0.0419\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('knn: ')\n",
    "knn = KNeighborsClassifier(n_neighbors=2, leaf_size = 50)\n",
    "knn_res = learn_test_classifier(X_train, y_train, X_test, y_test, knn)\n",
    "print()\n",
    "\n",
    "print('dt:')\n",
    "dt = DecisionTreeClassifier()\n",
    "dt_res = learn_test_classifier(X_train, y_train, X_test, y_test, dt)\n",
    "print()\n",
    "\n",
    "print('rf:')\n",
    "rf = RandomForestClassifier(criterion = 'entropy')\n",
    "rf_res = learn_test_classifier(X_train, y_train, X_test, y_test, rf)\n",
    "print()\n",
    "\n",
    "print('xgb: ')\n",
    "xgbM = xgb.XGBClassifier()\n",
    "xgb_res = learn_test_classifier(X_train, y_train, X_test, y_test, xgbM)\n",
    "print()\n",
    "\n",
    "print('lgb: ')\n",
    "lgbM = lgb.LGBMClassifier(n_estimators=200, silent=True,  num_leaves = 25, learning_rate = 0.03, random_state = 27, objective = 'multiclass')\n",
    "lgb_res = learn_test_classifier(X_train, y_train, X_test, y_test, lgbM)\n",
    "print()\n",
    "\n",
    "print('svc: ')\n",
    "svc = SVC(kernel= 'sigmoid', verbose = True, random_state = 24, probability = True)\n",
    "svc_res = learn_test_classifier(X_train, y_train, X_test, y_test, svc)\n",
    "print()\n",
    "\n",
    "'''print('mlp: ')\n",
    "mlp = MLPClassifier(hidden_layer_sizes=((m+p)*30,), verbose = False, max_iter= 50, tol = 0.0001)\n",
    "mlp_res = learn_test_classifier(X_train, y_train, X_test, y_test, mlp)\n",
    "print()''' #F1 - 0.00\n",
    "\n",
    "model1 = base_model((len(X_train.columns), ))\n",
    "history1 = train_cross_entropy(model1, X_train.values, cat_train_y, X_test.values, cat_test_y, 30, 2000)\n",
    "print('-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 4320x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight_f = lgbM.feature_importances_\n",
    "\n",
    "col_lab = []\n",
    "for i in X_train.columns:\n",
    "    col_lab.append(i)\n",
    "\n",
    "barplot(col_lab, weight_f, '', '', '', 'Вес признаков LGBMClassifier. Gaia дополнительный эксперимент', 60, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data_m.drop(columns = ['ref_epoch', 'time', 'transit_id', 'radius_val', 'parallax_over_error', 'dec_parallax_corr', 'dec_pmra_corr', 'dec_pmdec_corr',\n",
    "       'parallax_pmra_corr', 'parallax_pmdec_corr', 'pmra_pmdec_corr',])\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_1, y, test_size=0.7, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn: \n",
      "hamming_loss:  0.6232558139534884\n",
      "matthews_corrcoef:  0.09704290724542204\n",
      "accuracy_score:  0.3767441860465116\n",
      "precision_score:  0.07369433563908104\n",
      "recall_score:  0.09664779664779664\n",
      "f1_score:  0.07793422835585867\n",
      "\n",
      "dt:\n",
      "hamming_loss:  0.3209302325581395\n",
      "matthews_corrcoef:  0.5898183752593773\n",
      "accuracy_score:  0.6790697674418604\n",
      "precision_score:  0.35688616938616935\n",
      "recall_score:  0.3601676101676101\n",
      "f1_score:  0.32607179145640686\n",
      "\n",
      "rf:\n",
      "hamming_loss:  0.4046511627906977\n",
      "matthews_corrcoef:  0.4236312066005798\n",
      "accuracy_score:  0.5953488372093023\n",
      "precision_score:  0.33671776941007714\n",
      "recall_score: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.30685980685980685\n",
      "f1_score:  0.3009313029965204\n",
      "\n",
      "xgb: \n",
      "hamming_loss:  0.2930232558139535\n",
      "matthews_corrcoef:  0.6211841834004604\n",
      "accuracy_score:  0.7069767441860465\n",
      "precision_score:  0.3817476665248943\n",
      "recall_score:  0.38774003774003774\n",
      "f1_score:  0.36605957139893797\n",
      "\n",
      "lgb: \n",
      "hamming_loss:  0.3209302325581395\n",
      "matthews_corrcoef:  0.591691394255072\n",
      "accuracy_score:  0.6790697674418604\n",
      "precision_score:  0.34479686979686974\n",
      "recall_score:  0.3856088356088356\n",
      "f1_score:  0.3304358315525941\n",
      "\n",
      "svc: \n",
      "[LibSVM]hamming_loss:  0.5395348837209303\n",
      "matthews_corrcoef:  0.0\n",
      "accuracy_score:  0.4604651162790698\n",
      "precision_score:  0.017710196779964223\n",
      "recall_score:  0.038461538461538464\n",
      "f1_score:  0.02425281724644782\n",
      "\n",
      "mlp: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming_loss:  0.9395348837209302\n",
      "matthews_corrcoef:  0.021956508953537575\n",
      "accuracy_score:  0.06046511627906977\n",
      "precision_score:  0.004822763443453098\n",
      "recall_score:  0.052447552447552455\n",
      "f1_score:  0.008833030486573794\n",
      "\n",
      "Train on 92 samples, validate on 215 samples\n",
      "Epoch 1/30\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 1152341.5000 - accuracy: 0.0435 - val_loss: 236300.5156 - val_accuracy: 0.4605\n",
      "Epoch 2/30\n",
      "92/92 [==============================] - 0s 379us/step - loss: 467703.5938 - accuracy: 0.4022 - val_loss: 475070.3125 - val_accuracy: 0.0419\n",
      "Epoch 3/30\n",
      "92/92 [==============================] - 0s 390us/step - loss: 1165036.1250 - accuracy: 0.0435 - val_loss: 192198.2656 - val_accuracy: 0.0419\n",
      "Epoch 4/30\n",
      "92/92 [==============================] - 0s 444us/step - loss: 419977.3125 - accuracy: 0.0435 - val_loss: 680660.5625 - val_accuracy: 0.4605\n",
      "Epoch 5/30\n",
      "92/92 [==============================] - 0s 445us/step - loss: 444511.1250 - accuracy: 0.4783 - val_loss: 993037.6250 - val_accuracy: 0.4605\n",
      "Epoch 6/30\n",
      "92/92 [==============================] - 0s 401us/step - loss: 939730.9375 - accuracy: 0.4783 - val_loss: 821936.6875 - val_accuracy: 0.4605\n",
      "Epoch 7/30\n",
      "92/92 [==============================] - 0s 401us/step - loss: 604914.9375 - accuracy: 0.4783 - val_loss: 333817.7812 - val_accuracy: 0.4605\n",
      "Epoch 8/30\n",
      "92/92 [==============================] - 0s 412us/step - loss: 161134.8438 - accuracy: 0.4674 - val_loss: 60732.8789 - val_accuracy: 0.0419\n",
      "Epoch 9/30\n",
      "92/92 [==============================] - 0s 434us/step - loss: 270638.9688 - accuracy: 0.1739 - val_loss: 143592.4844 - val_accuracy: 0.0419\n",
      "Epoch 10/30\n",
      "92/92 [==============================] - 0s 358us/step - loss: 357977.5938 - accuracy: 0.0761 - val_loss: 54091.3477 - val_accuracy: 0.0419\n",
      "Epoch 11/30\n",
      "92/92 [==============================] - 0s 412us/step - loss: 41152.1055 - accuracy: 0.2609 - val_loss: 127040.2031 - val_accuracy: 0.4605\n",
      "Epoch 12/30\n",
      "92/92 [==============================] - 0s 423us/step - loss: 233978.7188 - accuracy: 0.4457 - val_loss: 119810.2969 - val_accuracy: 0.4605\n",
      "Epoch 13/30\n",
      "92/92 [==============================] - 0s 379us/step - loss: 132789.1094 - accuracy: 0.3913 - val_loss: 9036.1768 - val_accuracy: 0.2884\n",
      "Epoch 14/30\n",
      "92/92 [==============================] - 0s 379us/step - loss: 133559.2969 - accuracy: 0.2391 - val_loss: 46669.5195 - val_accuracy: 0.0558\n",
      "Epoch 15/30\n",
      "92/92 [==============================] - 0s 336us/step - loss: 78631.4531 - accuracy: 0.2609 - val_loss: 38863.7109 - val_accuracy: 0.4605\n",
      "Epoch 16/30\n",
      "92/92 [==============================] - 0s 271us/step - loss: 218504.8906 - accuracy: 0.2935 - val_loss: 212542.1719 - val_accuracy: 0.4605\n",
      "Epoch 17/30\n",
      "92/92 [==============================] - 0s 282us/step - loss: 151609.7031 - accuracy: 0.4130 - val_loss: 364232.3438 - val_accuracy: 0.4605\n",
      "Epoch 18/30\n",
      "92/92 [==============================] - 0s 434us/step - loss: 232775.8438 - accuracy: 0.4348 - val_loss: 379063.0625 - val_accuracy: 0.4605\n",
      "Epoch 19/30\n",
      "92/92 [==============================] - 0s 374us/step - loss: 361900.2500 - accuracy: 0.4457 - val_loss: 276835.7812 - val_accuracy: 0.4605\n",
      "Epoch 20/30\n",
      "92/92 [==============================] - 0s 304us/step - loss: 151775.8438 - accuracy: 0.4457 - val_loss: 80194.7188 - val_accuracy: 0.4605\n",
      "Epoch 21/30\n",
      "92/92 [==============================] - 0s 369us/step - loss: 132875.1094 - accuracy: 0.3696 - val_loss: 99151.8438 - val_accuracy: 0.0419\n",
      "Epoch 22/30\n",
      "92/92 [==============================] - 0s 423us/step - loss: 183210.0156 - accuracy: 0.1957 - val_loss: 143490.4844 - val_accuracy: 0.0419\n",
      "Epoch 23/30\n",
      "92/92 [==============================] - 0s 336us/step - loss: 328667.2500 - accuracy: 0.1304 - val_loss: 96403.2578 - val_accuracy: 0.0419\n",
      "Epoch 24/30\n",
      "92/92 [==============================] - 0s 325us/step - loss: 350403.4062 - accuracy: 0.1413 - val_loss: 71620.7656 - val_accuracy: 0.4605\n",
      "Epoch 25/30\n",
      "92/92 [==============================] - 0s 271us/step - loss: 180468.2969 - accuracy: 0.3370 - val_loss: 309580.2188 - val_accuracy: 0.4605\n",
      "Epoch 26/30\n",
      "92/92 [==============================] - 0s 260us/step - loss: 302444.4688 - accuracy: 0.4674 - val_loss: 409818.5312 - val_accuracy: 0.4605\n",
      "Epoch 27/30\n",
      "92/92 [==============================] - 0s 271us/step - loss: 205441.1719 - accuracy: 0.4891 - val_loss: 393530.6562 - val_accuracy: 0.4605\n",
      "Epoch 28/30\n",
      "92/92 [==============================] - 0s 260us/step - loss: 259285.1250 - accuracy: 0.4674 - val_loss: 271445.1562 - val_accuracy: 0.4605\n",
      "Epoch 29/30\n",
      "92/92 [==============================] - 0s 249us/step - loss: 215374.0938 - accuracy: 0.4457 - val_loss: 124972.7656 - val_accuracy: 0.4605\n",
      "Epoch 30/30\n",
      "92/92 [==============================] - 0s 282us/step - loss: 35802.7227 - accuracy: 0.3370 - val_loss: 18280.9609 - val_accuracy: 0.1256\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 4320x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('knn: ')\n",
    "knn = KNeighborsClassifier(n_neighbors=5, leaf_size = 30)\n",
    "knn_res = learn_test_classifier(X_train, y_train, X_test, y_test, knn)\n",
    "print()\n",
    "\n",
    "print('dt:')\n",
    "dt = DecisionTreeClassifier()\n",
    "dt_res = learn_test_classifier(X_train, y_train, X_test, y_test, dt)\n",
    "print()\n",
    "\n",
    "print('rf:')\n",
    "rf = RandomForestClassifier(criterion = 'entropy')\n",
    "rf_res = learn_test_classifier(X_train, y_train, X_test, y_test, rf)\n",
    "print()\n",
    "\n",
    "print('xgb: ')\n",
    "xgbM = xgb.XGBClassifier()\n",
    "xgb_res = learn_test_classifier(X_train, y_train, X_test, y_test, xgbM)\n",
    "print()\n",
    "\n",
    "print('lgb: ')\n",
    "lgbM = lgb.LGBMClassifier(n_estimators=200, silent=True,  num_leaves = 25, learning_rate = 0.03, random_state = 27, objective = 'multiclass')\n",
    "lgb_res = learn_test_classifier(X_train, y_train, X_test, y_test, lgbM)\n",
    "print()\n",
    "\n",
    "print('svc: ')\n",
    "svc = SVC(kernel='rbf', max_iter = 80, verbose = True, random_state = 24, probability = True)\n",
    "svc_res = learn_test_classifier(X_train, y_train, X_test, y_test, svc)\n",
    "print()\n",
    "\n",
    "print('mlp: ')\n",
    "mlp = MLPClassifier(hidden_layer_sizes=((m+p)*30,), verbose = False, max_iter= 50, tol = 0.0001)\n",
    "mlp_res = learn_test_classifier(X_train, y_train, X_test, y_test, mlp)\n",
    "print()\n",
    "\n",
    "model1 = base_model((len(X_train.columns), ))\n",
    "history1 = train_cross_entropy(model1, X_train.values, cat_train_y, X_test.values, cat_test_y, 30, 2000)\n",
    "print('-------------------------------')\n",
    "\n",
    "weight_f = lgbM.feature_importances_\n",
    "\n",
    "col_lab = []\n",
    "for i in X_train.columns:\n",
    "    col_lab.append(i)\n",
    "\n",
    "barplot(col_lab, weight_f, '', '', '', 'Вес признаков LGBMClassifier. Gaia дополнительный эксперимент', 60, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "print(len(y.drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307\n",
      "143\n"
     ]
    }
   ],
   "source": [
    "k = y.where(lambda x: x == max(y)).dropna()\n",
    "print(len(y))\n",
    "print(len(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка на нормализованных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#делим данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.7, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y = []\n",
    "\n",
    "for i in y:\n",
    "    el = [0.0 for i in range(p)]\n",
    "    el[i] = 1.0\n",
    "    new_y.append(el)\n",
    "    \n",
    "cat_y = to_categorical(y.values)\n",
    "\n",
    "cat_train_y = to_categorical(y_train.values)\n",
    "cat_test_y = to_categorical(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn: \n",
      "hamming_loss:  0.6837209302325581\n",
      "matthews_corrcoef:  0.03307143298727871\n",
      "accuracy_score:  0.31627906976744186\n",
      "precision_score:  0.061896436896436896\n",
      "recall_score:  0.057942057942057944\n",
      "f1_score:  0.05822716859506157\n",
      "\n",
      "dt:\n",
      "hamming_loss:  0.37209302325581395\n",
      "matthews_corrcoef:  0.5218670671434732\n",
      "accuracy_score:  0.627906976744186\n",
      "precision_score:  0.2818333376025684\n",
      "recall_score:  0.31120546120546116\n",
      "f1_score:  0.27529955424692265\n",
      "\n",
      "rf:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming_loss:  0.413953488372093\n",
      "matthews_corrcoef:  0.40479287956924886\n",
      "accuracy_score:  0.586046511627907\n",
      "precision_score:  0.30201256483307765\n",
      "recall_score:  0.2760739260739261\n",
      "f1_score:  0.2537602906966302\n",
      "\n",
      "svc: \n",
      "[LibSVM]hamming_loss:  0.5395348837209303\n",
      "matthews_corrcoef:  0.0\n",
      "accuracy_score:  0.4604651162790698\n",
      "precision_score:  0.017710196779964223\n",
      "recall_score:  0.038461538461538464\n",
      "f1_score:  0.02425281724644782\n",
      "\n",
      "mlp: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming_loss:  0.5395348837209303\n",
      "matthews_corrcoef:  0.10726515738934929\n",
      "accuracy_score:  0.4604651162790698\n",
      "precision_score:  0.06953165881737311\n",
      "recall_score:  0.060994560994561006\n",
      "f1_score:  0.05580851134958045\n",
      "\n",
      "Train on 92 samples, validate on 215 samples\n",
      "Epoch 1/30\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 3.2649 - accuracy: 0.0543 - val_loss: 2.8880 - val_accuracy: 0.4605\n",
      "Epoch 2/30\n",
      "92/92 [==============================] - 0s 304us/step - loss: 2.8413 - accuracy: 0.4783 - val_loss: 2.5822 - val_accuracy: 0.4605\n",
      "Epoch 3/30\n",
      "92/92 [==============================] - 0s 369us/step - loss: 2.4911 - accuracy: 0.4783 - val_loss: 2.4320 - val_accuracy: 0.4605\n",
      "Epoch 4/30\n",
      "92/92 [==============================] - 0s 336us/step - loss: 2.3004 - accuracy: 0.4783 - val_loss: 2.5260 - val_accuracy: 0.4605\n",
      "Epoch 5/30\n",
      "92/92 [==============================] - 0s 390us/step - loss: 2.3267 - accuracy: 0.4783 - val_loss: 2.6190 - val_accuracy: 0.4605\n",
      "Epoch 6/30\n",
      "92/92 [==============================] - 0s 401us/step - loss: 2.3528 - accuracy: 0.4783 - val_loss: 2.5829 - val_accuracy: 0.4605\n",
      "Epoch 7/30\n",
      "92/92 [==============================] - 0s 347us/step - loss: 2.2508 - accuracy: 0.4783 - val_loss: 2.4977 - val_accuracy: 0.4605\n",
      "Epoch 8/30\n",
      "92/92 [==============================] - 0s 379us/step - loss: 2.1690 - accuracy: 0.4783 - val_loss: 2.4384 - val_accuracy: 0.4605\n",
      "Epoch 9/30\n",
      "92/92 [==============================] - 0s 390us/step - loss: 2.0639 - accuracy: 0.4783 - val_loss: 2.4311 - val_accuracy: 0.4605\n",
      "Epoch 10/30\n",
      "92/92 [==============================] - 0s 369us/step - loss: 2.0209 - accuracy: 0.4783 - val_loss: 2.4511 - val_accuracy: 0.4605\n",
      "Epoch 11/30\n",
      "92/92 [==============================] - 0s 304us/step - loss: 2.0248 - accuracy: 0.4783 - val_loss: 2.4656 - val_accuracy: 0.4651\n",
      "Epoch 12/30\n",
      "92/92 [==============================] - 0s 347us/step - loss: 1.9903 - accuracy: 0.4891 - val_loss: 2.4614 - val_accuracy: 0.4744\n",
      "Epoch 13/30\n",
      "92/92 [==============================] - 0s 336us/step - loss: 1.9480 - accuracy: 0.5109 - val_loss: 2.4433 - val_accuracy: 0.4744\n",
      "Epoch 14/30\n",
      "92/92 [==============================] - 0s 379us/step - loss: 1.9052 - accuracy: 0.4891 - val_loss: 2.4265 - val_accuracy: 0.4744\n",
      "Epoch 15/30\n",
      "92/92 [==============================] - 0s 325us/step - loss: 1.8066 - accuracy: 0.5109 - val_loss: 2.4264 - val_accuracy: 0.4651\n",
      "Epoch 16/30\n",
      "92/92 [==============================] - 0s 314us/step - loss: 1.7433 - accuracy: 0.4891 - val_loss: 2.4475 - val_accuracy: 0.4651\n",
      "Epoch 17/30\n",
      "92/92 [==============================] - 0s 314us/step - loss: 1.6895 - accuracy: 0.4891 - val_loss: 2.4744 - val_accuracy: 0.4651\n",
      "Epoch 18/30\n",
      "92/92 [==============================] - 0s 282us/step - loss: 1.6829 - accuracy: 0.4891 - val_loss: 2.4861 - val_accuracy: 0.4651\n",
      "Epoch 19/30\n",
      "92/92 [==============================] - 0s 369us/step - loss: 1.6091 - accuracy: 0.4891 - val_loss: 2.4759 - val_accuracy: 0.4698\n",
      "Epoch 20/30\n",
      "92/92 [==============================] - 0s 282us/step - loss: 1.5840 - accuracy: 0.5000 - val_loss: 2.4572 - val_accuracy: 0.4744\n",
      "Epoch 21/30\n",
      "92/92 [==============================] - 0s 293us/step - loss: 1.5126 - accuracy: 0.5217 - val_loss: 2.4476 - val_accuracy: 0.4791\n",
      "Epoch 22/30\n",
      "92/92 [==============================] - 0s 271us/step - loss: 1.4767 - accuracy: 0.5435 - val_loss: 2.4521 - val_accuracy: 0.4791\n",
      "Epoch 23/30\n",
      "92/92 [==============================] - 0s 282us/step - loss: 1.4210 - accuracy: 0.5543 - val_loss: 2.4627 - val_accuracy: 0.4791\n",
      "Epoch 24/30\n",
      "92/92 [==============================] - 0s 293us/step - loss: 1.3696 - accuracy: 0.5543 - val_loss: 2.4708 - val_accuracy: 0.4791\n",
      "Epoch 25/30\n",
      "92/92 [==============================] - 0s 271us/step - loss: 1.3189 - accuracy: 0.5652 - val_loss: 2.4778 - val_accuracy: 0.4837\n",
      "Epoch 26/30\n",
      "92/92 [==============================] - 0s 260us/step - loss: 1.2651 - accuracy: 0.5652 - val_loss: 2.4919 - val_accuracy: 0.4791\n",
      "Epoch 27/30\n",
      "92/92 [==============================] - 0s 260us/step - loss: 1.2258 - accuracy: 0.5761 - val_loss: 2.5162 - val_accuracy: 0.4744\n",
      "Epoch 28/30\n",
      "92/92 [==============================] - 0s 271us/step - loss: 1.1552 - accuracy: 0.5978 - val_loss: 2.5442 - val_accuracy: 0.4744\n",
      "Epoch 29/30\n",
      "92/92 [==============================] - 0s 325us/step - loss: 1.1399 - accuracy: 0.5978 - val_loss: 2.5640 - val_accuracy: 0.4744\n",
      "Epoch 30/30\n",
      "92/92 [==============================] - 0s 260us/step - loss: 1.0925 - accuracy: 0.5978 - val_loss: 2.5704 - val_accuracy: 0.4698\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('knn: ')\n",
    "knn = KNeighborsClassifier(n_neighbors=5, leaf_size = 30)\n",
    "knn_res = learn_test_classifier(X_train, y_train, X_test, y_test, knn)\n",
    "print()\n",
    "\n",
    "print('dt:')\n",
    "dt = DecisionTreeClassifier()\n",
    "dt_res = learn_test_classifier(X_train, y_train, X_test, y_test, dt)\n",
    "print()\n",
    "\n",
    "print('rf:')\n",
    "rf = RandomForestClassifier(criterion = 'entropy')\n",
    "rf_res = learn_test_classifier(X_train, y_train, X_test, y_test, rf)\n",
    "print()\n",
    "\n",
    "print('svc: ')\n",
    "svc = SVC(kernel='rbf', max_iter = 80, verbose = True, random_state = 24, probability = True)\n",
    "svc_res = learn_test_classifier(X_train, y_train, X_test, y_test, svc)\n",
    "print()\n",
    "\n",
    "print('mlp: ')\n",
    "mlp = MLPClassifier(hidden_layer_sizes=((m+p)*30,), verbose = False, max_iter= 50, tol = 0.0001)\n",
    "mlp_res = learn_test_classifier(X_train, y_train, X_test, y_test, mlp)\n",
    "print()\n",
    "\n",
    "model1 = base_model((len(data_m.columns), ))\n",
    "history1 = train_cross_entropy(model1, X_train.values, cat_train_y, X_test.values, cat_test_y, 30, 2000)\n",
    "print('-------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластеризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completeness_score:  0.2444768284662575\n",
      "adjusted_rand_score:  0.010274429107949614\n",
      "v_measure_score:  0.23917867178629423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster1 = SpectralClustering(n_clusters = n, random_state = 25, affinity = 'nearest_neighbors', n_neighbors=3)#'rbf')#\n",
    "y_test1 = y\n",
    "data1 = data_m\n",
    "cluster1.fit(data1)\n",
    "res = cluster1.labels_\n",
    "\n",
    "print('completeness_score: ', completeness_score(y_test1, res))\n",
    "print('adjusted_rand_score: ', adjusted_rand_score(y_test1, res))\n",
    "print('v_measure_score: ', v_measure_score(y_test1, res))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completeness_score:  0.24071492987726076\n",
      "adjusted_rand_score:  0.0012520211573003972\n",
      "v_measure_score:  0.2793149311051679\n"
     ]
    }
   ],
   "source": [
    "cluster2 = AgglomerativeClustering(n_clusters = n, affinity = 'euclidean')\n",
    "cluster2.fit(data1)\n",
    "res = cluster2.labels_\n",
    "\n",
    "print('completeness_score: ', completeness_score(y_test1, res))\n",
    "print('adjusted_rand_score: ', adjusted_rand_score(y_test1, res))\n",
    "print('v_measure_score: ', v_measure_score(y_test1, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completeness_score:  0.2401698312177716\n",
      "adjusted_rand_score:  -0.003322683752815329\n",
      "v_measure_score:  0.2777365322815022\n"
     ]
    }
   ],
   "source": [
    "cluster3 = KMeans(n_clusters= n, init = 'random', n_init=5, max_iter=500)\n",
    "cluster3.fit(data1)\n",
    "res = cluster3.labels_\n",
    "\n",
    "print('completeness_score: ', completeness_score(y_test1, res))\n",
    "print('adjusted_rand_score: ', adjusted_rand_score(y_test1, res))\n",
    "print('v_measure_score: ', v_measure_score(y_test1, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
